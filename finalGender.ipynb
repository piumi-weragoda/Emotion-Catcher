{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSrNjeC9o9Of",
        "outputId": "896d7004-c93e-4c2b-906c-4442b9f9594a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Discard Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "mqSySyAbpRXF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EOJazBDZpcBo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the current directory\n",
        "cwd = os.getcwd()\n",
        "print(cwd)\n",
        "\n",
        "# change the current directory to extract files\n",
        "os.chdir('/')\n",
        "\n",
        "# Print the current directory for confirmation\n",
        "cwd = os.getcwd()\n",
        "print(cwd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct3uA6mppla4",
        "outputId": "adfe6402-250f-4174-a82c-aa957161f427"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the zip file and extract\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ],
      "metadata": {
        "id": "Mpmwn444pm2h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load balanced.csv and prints begining\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/GenderDetection/balanced-all.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p251ShAqpqWy",
        "outputId": "2bb194e2-9704-4cab-aa9a-6424823ffcf3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                filename  gender\n",
              "0  data/cv-other-train/sample-069205.npy  female\n",
              "1  data/cv-valid-train/sample-063134.npy  female\n",
              "2  data/cv-other-train/sample-080873.npy  female\n",
              "3  data/cv-other-train/sample-105595.npy  female\n",
              "4  data/cv-valid-train/sample-144613.npy  female"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-097f5805-9289-4198-846e-8326f3187c9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/cv-other-train/sample-069205.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/cv-valid-train/sample-063134.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/cv-other-train/sample-080873.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/cv-other-train/sample-105595.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/cv-valid-train/sample-144613.npy</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-097f5805-9289-4198-846e-8326f3187c9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-097f5805-9289-4198-846e-8326f3187c9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-097f5805-9289-4198-846e-8326f3187c9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load balanced.csv and prints end\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8okieyonps9n",
        "outputId": "69bcc2b4-9775-4acd-c85d-1840242173eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    filename gender\n",
              "66933  data/cv-valid-train/sample-171098.npy   male\n",
              "66934  data/cv-other-train/sample-022864.npy   male\n",
              "66935  data/cv-valid-train/sample-080933.npy   male\n",
              "66936  data/cv-other-train/sample-012026.npy   male\n",
              "66937  data/cv-other-train/sample-013841.npy   male"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dab66c49-5c94-4000-ac2f-bcaec5926b50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>66933</th>\n",
              "      <td>data/cv-valid-train/sample-171098.npy</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66934</th>\n",
              "      <td>data/cv-other-train/sample-022864.npy</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66935</th>\n",
              "      <td>data/cv-valid-train/sample-080933.npy</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66936</th>\n",
              "      <td>data/cv-other-train/sample-012026.npy</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66937</th>\n",
              "      <td>data/cv-other-train/sample-013841.npy</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dab66c49-5c94-4000-ac2f-bcaec5926b50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dab66c49-5c94-4000-ac2f-bcaec5926b50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dab66c49-5c94-4000-ac2f-bcaec5926b50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get total samples\n",
        "n_samples = len(df)\n",
        "# get total male samples\n",
        "n_male_samples = len(df[df['gender'] == 'male'])\n",
        "# get total female samples\n",
        "n_female_samples = len(df[df['gender'] == 'female'])\n",
        "print(\"Total samples:\", n_samples)\n",
        "print(\"Total male samples:\", n_male_samples)\n",
        "print(\"Total female samples:\", n_female_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWjXVN2XpwQG",
        "outputId": "b6d9f8be-0780-4802-a9f0-348d106790d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 66938\n",
            "Total male samples: 33469\n",
            "Total female samples: 33469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2int = {\n",
        "    \"male\": 1,\n",
        "    \"female\": 0\n",
        "}\n",
        "\n",
        "def load_data(vector_length=128):\n",
        "    \"\"\"A function to load gender recognition dataset from `data` folder\n",
        "    After the second run, this will load from results/features.npy and results/labels.npy files\n",
        "    as it is much faster!\"\"\"\n",
        "    # make sure results folder exists\n",
        "    if not os.path.isdir(\"results\"):\n",
        "        os.mkdir(\"results\")\n",
        "    # if features & labels already loaded individually and bundled, load them from there instead\n",
        "    if os.path.isfile(\"results/features.npy\") and os.path.isfile(\"results/labels.npy\"):\n",
        "        X = np.load(\"results/features.npy\")\n",
        "        y = np.load(\"results/labels.npy\")\n",
        "        return X, y\n",
        "    # read dataframe\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/GenderDetection/balanced-all.csv\")\n",
        "    # get total samples\n",
        "    n_samples = len(df)\n",
        "    # get total male samples\n",
        "    n_male_samples = len(df[df['gender'] == 'male'])\n",
        "    # get total female samples\n",
        "    n_female_samples = len(df[df['gender'] == 'female'])\n",
        "    print(\"Total samples:\", n_samples)\n",
        "    print(\"Total male samples:\", n_male_samples)\n",
        "    print(\"Total female samples:\", n_female_samples)\n",
        "    # initialize an empty array for all audio features\n",
        "    X = np.zeros((n_samples, vector_length))\n",
        "    # initialize an empty array for all audio labels (1 for male and 0 for female)\n",
        "    y = np.zeros((n_samples, 1))\n",
        "    for i, (filename, gender) in tqdm.tqdm(enumerate(zip(df['filename'], df['gender'])), \"Loading data\", total=n_samples):\n",
        "        features = np.load(filename)\n",
        "        X[i] = features\n",
        "        y[i] = label2int[gender]\n",
        "    # save the audio features and labels into files\n",
        "    # so we won't load each one of them next run\n",
        "    np.save(\"results/features\", X)\n",
        "    np.save(\"results/labels\", y)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "JXTwpe6_pzwi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(X, y, test_size=0.1, valid_size=0.1):\n",
        "    # split training set and testing set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=7)\n",
        "    # split training set and validation set\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=7)\n",
        "    # return a dictionary of values\n",
        "    return {\n",
        "        \"X_train\": X_train,\n",
        "        \"X_valid\": X_valid,\n",
        "        \"X_test\": X_test,\n",
        "        \"y_train\": y_train,\n",
        "        \"y_valid\": y_valid,\n",
        "        \"y_test\": y_test\n",
        "    }"
      ],
      "metadata": {
        "id": "WDIidcuKp5sR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "X, y = load_data()\n",
        "# split the data into training, validation and testing sets\n",
        "data = split_data(X, y, test_size=0.1, valid_size=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1HxjvVup9CF",
        "outputId": "f9ae8f5f-0c3e-492d-ebbc-758827b7b48a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 66938\n",
            "Total male samples: 33469\n",
            "Total female samples: 33469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 66938/66938 [00:33<00:00, 2012.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints the shape of traning, validation and test datasets\n",
        "print(np.shape(data[\"X_train\"]))\n",
        "print(np.shape(data[\"X_valid\"]))\n",
        "print(np.shape(data[\"X_test\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVp_v8pbqBRD",
        "outputId": "5b788934-1879-474a-c8eb-545c3786dd88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54219, 128)\n",
            "(6025, 128)\n",
            "(6694, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing required packages\n",
        "!pip install pydub\n",
        "!pip install noisereduce\n",
        "!pip install json-tricks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTXHeB0tqEfg",
        "outputId": "c4e30dba-d318-415e-fdc0-f8be59a31a1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting noisereduce\n",
            "  Downloading noisereduce-2.0.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from noisereduce) (3.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from noisereduce) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from noisereduce) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from noisereduce) (4.64.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (from noisereduce) (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (1.2.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (3.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (0.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (23.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (0.56.4)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (1.2.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa->noisereduce) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa->noisereduce) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa->noisereduce) (0.39.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa->noisereduce) (2.25.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa->noisereduce) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->noisereduce) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.21)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa->noisereduce) (3.15.0)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting json-tricks\n",
            "  Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
            "Installing collected packages: json-tricks\n",
            "Successfully installed json-tricks-3.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vector_length=128):\n",
        "    \"\"\"5 hidden dense layers from 256 units to 64, not the best model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_shape=(vector_length,)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dropout(0.3))\n",
        "    # one output neuron with sigmoid activation function, 0 means female, 1 means male\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    # using binary crossentropy as it's male/female classification (binary)\n",
        "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
        "    # print summary of the model\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "j_n69uKDqHuh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the model\n",
        "model = create_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCHka9XHqLru",
        "outputId": "aac967b5-ece8-4270-efb1-d36a70877052"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 156,545\n",
            "Trainable params: 156,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import callbacks "
      ],
      "metadata": {
        "id": "MFAywoOHqRil"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks functions\n",
        "checkpoint_path = '/content/drive/My Drive/Colab Notebooks/best_weights.hdf5'\n",
        "\n",
        "#-> Save the best weights\n",
        "mcp_save = callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True,\n",
        "                           monitor='val_categorical_accuracy',\n",
        "                           mode='max')"
      ],
      "metadata": {
        "id": "XZqxknqbqSg1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use tensorboard to view metrics\n",
        "tensorboard = TensorBoard(log_dir=\"logs\")\n",
        "# define early stopping to stop training after 5 epochs of not improving\n",
        "early_stopping = EarlyStopping(mode=\"min\", patience=5, restore_best_weights=True)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "# train the model using the training set and validating using validation set\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n",
        "          callbacks=[tensorboard, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu1fgeaZqVr6",
        "outputId": "999b7101-7939-46d0-923b-3bf306399d23"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "848/848 [==============================] - 17s 16ms/step - loss: 0.5579 - accuracy: 0.7630 - val_loss: 0.3694 - val_accuracy: 0.8473\n",
            "Epoch 2/100\n",
            "848/848 [==============================] - 17s 20ms/step - loss: 0.4135 - accuracy: 0.8389 - val_loss: 0.3481 - val_accuracy: 0.8627\n",
            "Epoch 3/100\n",
            "848/848 [==============================] - 8s 10ms/step - loss: 0.3765 - accuracy: 0.8539 - val_loss: 0.3215 - val_accuracy: 0.8666\n",
            "Epoch 4/100\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 0.3623 - accuracy: 0.8615 - val_loss: 0.3177 - val_accuracy: 0.8802\n",
            "Epoch 5/100\n",
            "848/848 [==============================] - 10s 11ms/step - loss: 0.3419 - accuracy: 0.8685 - val_loss: 0.3015 - val_accuracy: 0.8825\n",
            "Epoch 6/100\n",
            "848/848 [==============================] - 12s 14ms/step - loss: 0.3398 - accuracy: 0.8713 - val_loss: 0.2854 - val_accuracy: 0.8923\n",
            "Epoch 7/100\n",
            "848/848 [==============================] - 11s 12ms/step - loss: 0.3229 - accuracy: 0.8757 - val_loss: 0.2828 - val_accuracy: 0.8933\n",
            "Epoch 8/100\n",
            "848/848 [==============================] - 12s 14ms/step - loss: 0.3144 - accuracy: 0.8790 - val_loss: 0.2680 - val_accuracy: 0.8998\n",
            "Epoch 9/100\n",
            "848/848 [==============================] - 16s 19ms/step - loss: 0.3129 - accuracy: 0.8807 - val_loss: 0.2809 - val_accuracy: 0.8908\n",
            "Epoch 10/100\n",
            "848/848 [==============================] - 9s 11ms/step - loss: 0.3068 - accuracy: 0.8836 - val_loss: 0.2609 - val_accuracy: 0.8964\n",
            "Epoch 11/100\n",
            "848/848 [==============================] - 12s 15ms/step - loss: 0.3036 - accuracy: 0.8833 - val_loss: 0.2666 - val_accuracy: 0.8951\n",
            "Epoch 12/100\n",
            "848/848 [==============================] - 12s 14ms/step - loss: 0.2998 - accuracy: 0.8869 - val_loss: 0.2510 - val_accuracy: 0.8979\n",
            "Epoch 13/100\n",
            "848/848 [==============================] - 8s 9ms/step - loss: 0.2960 - accuracy: 0.8875 - val_loss: 0.2729 - val_accuracy: 0.8913\n",
            "Epoch 14/100\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 0.2917 - accuracy: 0.8897 - val_loss: 0.2479 - val_accuracy: 0.9032\n",
            "Epoch 15/100\n",
            "848/848 [==============================] - 14s 17ms/step - loss: 0.2835 - accuracy: 0.8927 - val_loss: 0.2502 - val_accuracy: 0.9016\n",
            "Epoch 16/100\n",
            "848/848 [==============================] - 14s 16ms/step - loss: 0.2828 - accuracy: 0.8929 - val_loss: 0.2501 - val_accuracy: 0.9016\n",
            "Epoch 17/100\n",
            "848/848 [==============================] - 9s 10ms/step - loss: 0.2801 - accuracy: 0.8941 - val_loss: 0.2449 - val_accuracy: 0.9066\n",
            "Epoch 18/100\n",
            "848/848 [==============================] - 10s 12ms/step - loss: 0.2793 - accuracy: 0.8941 - val_loss: 0.2468 - val_accuracy: 0.9085\n",
            "Epoch 19/100\n",
            "848/848 [==============================] - 14s 16ms/step - loss: 0.2808 - accuracy: 0.8947 - val_loss: 0.2531 - val_accuracy: 0.9007\n",
            "Epoch 20/100\n",
            "848/848 [==============================] - 17s 20ms/step - loss: 0.2761 - accuracy: 0.8972 - val_loss: 0.2424 - val_accuracy: 0.9061\n",
            "Epoch 21/100\n",
            "848/848 [==============================] - 13s 16ms/step - loss: 0.2768 - accuracy: 0.8978 - val_loss: 0.2684 - val_accuracy: 0.9011\n",
            "Epoch 22/100\n",
            "848/848 [==============================] - 9s 10ms/step - loss: 0.2773 - accuracy: 0.8944 - val_loss: 0.2382 - val_accuracy: 0.9112\n",
            "Epoch 23/100\n",
            "848/848 [==============================] - 8s 9ms/step - loss: 0.2736 - accuracy: 0.8979 - val_loss: 0.2389 - val_accuracy: 0.9097\n",
            "Epoch 24/100\n",
            "848/848 [==============================] - 10s 11ms/step - loss: 0.2688 - accuracy: 0.8994 - val_loss: 0.2297 - val_accuracy: 0.9125\n",
            "Epoch 25/100\n",
            "848/848 [==============================] - 7s 9ms/step - loss: 0.2680 - accuracy: 0.9007 - val_loss: 0.2477 - val_accuracy: 0.9109\n",
            "Epoch 26/100\n",
            "848/848 [==============================] - 10s 11ms/step - loss: 0.2664 - accuracy: 0.8997 - val_loss: 0.2468 - val_accuracy: 0.9090\n",
            "Epoch 27/100\n",
            "848/848 [==============================] - 8s 9ms/step - loss: 0.2699 - accuracy: 0.8982 - val_loss: 0.2452 - val_accuracy: 0.9094\n",
            "Epoch 28/100\n",
            "848/848 [==============================] - 10s 12ms/step - loss: 0.2628 - accuracy: 0.9014 - val_loss: 0.2452 - val_accuracy: 0.9074\n",
            "Epoch 29/100\n",
            "848/848 [==============================] - 11s 13ms/step - loss: 0.2656 - accuracy: 0.9010 - val_loss: 0.2319 - val_accuracy: 0.9132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating the model using the testing set\n",
        "print(f\"Evaluating the model using {len(data['X_test'])} samples...\")\n",
        "loss, accuracy = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAYzXo1gsk_M",
        "outputId": "673b30e1-e838-47d2-9adc-111bbca102ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model using 6694 samples...\n",
            "Loss: 0.2350\n",
            "Accuracy: 91.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation score\n",
        "loss,acc = model.evaluate(data[\"X_valid\"], data[\"y_valid\"], verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8twvYNGsqkv",
        "outputId": "1cc43418-9379-40cc-a942-42cba23834b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 - 1s - loss: 0.2297 - accuracy: 0.9125 - 976ms/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the relevant libraries\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "cq8UrKQlswfr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss prediction for trained and validation dataset\n",
        "\n",
        "plt.plot(history.history['loss'], label='Loss (training data)')\n",
        "plt.plot(history.history['val_loss'], label='Loss (validation data)')\n",
        "plt.title('Loss for train and validation')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BRLg6g7hs6Dl",
        "outputId": "f44c052d-6083-432a-8b8b-c560d04aba38"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to a file\n",
        "model.save(\"/content/drive/MyDrive/GenderDetection/model.h5\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTHuBfSwqZNj",
        "outputId": "6fa48dbf-e9c3-4ea0-c2d5-6f6fc6cbbdfe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.sequential.Sequential object at 0x7f74bbd83e50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "model_json = model.to_json()\n",
        "saved_model_path = '/content/drive/MyDrive/GenderDetection/modelLSTM.json'\n",
        "saved_weights_path = '/content/drive/MyDrive/GenderDetection/modelLSTM_weights.h5'\n",
        "\n",
        "\n",
        "with open(saved_model_path, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "model.save_weights(saved_weights_path)\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGh8uU7uvv7N",
        "outputId": "80a47b29-a6b0-4292-ec07-3a9eaa96cb87"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn1xbNw3twl4",
        "outputId": "e4549937-780d-4996-cbca-321ab491ef98"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libasound2-dev is already the newest version (1.2.2-2.1ubuntu2.5).\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 926 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libportaudio2 amd64 19.6.0-1build1 [65.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libportaudiocpp0 amd64 19.6.0-1build1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 portaudio19-dev amd64 19.6.0-1build1 [106 kB]\n",
            "Fetched 188 kB in 0s (741 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 128215 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1build1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1build1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1build1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1build1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1build1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1build1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1build1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1build1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1build1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyAudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUu4qO2PtyLh",
        "outputId": "ff13c22c-5b67-4db6-f94b-82dea9ccf2ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyAudio\n",
            "  Downloading PyAudio-0.2.13.tar.gz (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: PyAudio\n",
            "  Building wheel for PyAudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyAudio: filename=PyAudio-0.2.13-cp38-cp38-linux_x86_64.whl size=69725 sha256=534d0828c9adb6cf06fa6ceb981b348bb5d9eb8e9894fe45cd43a06443fec718\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/64/0b/9a483698792349f565ecc45c5ee3f1efb2ce79464f6d9daf53\n",
            "Successfully built PyAudio\n",
            "Installing collected packages: PyAudio\n",
            "Successfully installed PyAudio-0.2.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for External Inputs and Validation\n",
        "# Retrive the file path\n",
        "file_name = \"/content/drive/MyDrive/VoiceData/1008_IEO_SAD_HI.wav\""
      ],
      "metadata": {
        "id": "lzOK70hUtWz3"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load file data\n",
        "import librosa\n",
        "array, sample_rate = librosa.core.load(file_name)"
      ],
      "metadata": {
        "id": "iEUDTWDRwtNd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    \"\"\"\n",
        "    Extract feature from audio file `file_name`\n",
        "        Features supported:\n",
        "            - MFCC (mfcc)\n",
        "            - Chroma (chroma)\n",
        "            - MEL Spectrogram Frequency (mel)\n",
        "            - Contrast (contrast)\n",
        "            - Tonnetz (tonnetz)\n",
        "        e.g:\n",
        "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
        "    \"\"\"\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    # array, sample_rate = librosa.core.load(file_name)\n",
        "    if chroma or contrast:\n",
        "        stft = np.abs(librosa.stft(array))\n",
        "    result = np.array([])\n",
        "    if mfcc:\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=array, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        result = np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel = np.mean(librosa.feature.melspectrogram(array, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, mel))\n",
        "    if contrast:\n",
        "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, contrast))\n",
        "    if tonnetz:\n",
        "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(array), sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, tonnetz))\n",
        "    return result\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # load the saved model (after training)\n",
        "    # model = pickle.load(open(\"result/mlp_classifier.model\", \"rb\"))\n",
        "    # from utils import load_data, split_data, create_model\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
        "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
        "    parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
        "    args = parser.parse_args()\n",
        "    file = args.file\n",
        "    # construct the model\n",
        "    model = create_model()\n",
        "    # load the saved/trained weights\n",
        "    model.load_weights(\"/content/drive/MyDrive/GenderDetection/model.h5\")\n",
        "    features = extract_feature(file, mel=True).reshape(1, -1)\n",
        "    # predict the gender!\n",
        "    male_prob = model.predict(features)[0][0]\n",
        "    female_prob = 1 - male_prob\n",
        "    gender = \"male\" if male_prob > female_prob else \"female\"\n",
        "    # show the result!\n",
        "    print(\"Result:\", gender)\n",
        "    print(f\"Probabilities:     Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")\n",
        "\n",
        "    # Results Demostration\n",
        "    gender = ['Male', 'Female']\n",
        "    Probability = [male_prob, female_prob]\n",
        "    fig = plt.figure(figsize = (3, 6))\n",
        "    plt.bar(gender, Probability, color = 'darkblue')\n",
        "    plt.ylabel(\"Probabilty (%)\")\n",
        "    plt.title(\"Percentage Predictions\")\n",
        "    plt.show()\n",
        "\n",
        "    print(file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "id": "b5QVpniVw6hB",
        "outputId": "ae8e887b-80c5-424b-8583-dddf4ea1c60b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 156,545\n",
            "Trainable params: 156,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "Result: female\n",
            "Probabilities:     Male: 4.94%    Female: 95.06%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 216x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/VoiceData/1008_IEO_SAD_HI.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yeEgF8wXx28h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}